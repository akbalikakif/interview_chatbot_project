"""
speech_to_text.py
Google Cloud Speech-to-Text API kullanarak ses kaydÄ±nÄ± metne dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r.

Ã–zellikler:
- Ã‡ok dilli algÄ±lama (TÃ¼rkÃ§e + Ä°ngilizce)
- Otomatik sessizlik algÄ±lama
- GeliÅŸmiÅŸ model (latest_long) kullanÄ±mÄ±
- Teknik terimlerin doÄŸru algÄ±lanmasÄ±
"""

import os
import io
import pyaudio
import wave
import time
from datetime import datetime
from dotenv import load_dotenv
from google.cloud import speech
import numpy as np

# .env dosyasÄ±ndaki deÄŸiÅŸkenleri yÃ¼kle
load_dotenv()
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = os.getenv("GOOGLE_APPLICATION_CREDENTIALS")

# Ses kaydÄ± ayarlarÄ±
CHUNK = 1024
FORMAT = pyaudio.paInt16
CHANNELS = 1
RATE = 16000  # Google Cloud Speech-to-Text iÃ§in Ã¶nerilen sample rate

# Sessizlik algÄ±lama parametreleri
SILENCE_THRESHOLD = 500  # Sessizlik eÅŸiÄŸi (amplitude deÄŸeri)
SILENCE_DURATION = int(3 * RATE / CHUNK)  # 3 saniye sessizlik (chunk sayÄ±sÄ±)
MIN_RECORDING_DURATION = 2  # Minimum kayÄ±t sÃ¼resi (saniye)
INITIAL_GRACE_PERIOD = int(3 * RATE / CHUNK)  # BaÅŸlangÄ±Ã§ta 3 saniye bekleme (konuÅŸmaya hazÄ±rlanma)

# Data klasÃ¶rÃ¼nÃ¼ oluÅŸtur
DATA_DIR = "data"
if not os.path.exists(DATA_DIR):
    os.makedirs(DATA_DIR)

def calculate_rms(audio_data):
    """Ses verisinin RMS (Root Mean Square) deÄŸerini hesaplar - ses seviyesini Ã¶lÃ§mek iÃ§in"""
    audio_array = np.frombuffer(audio_data, dtype=np.int16)
    rms = np.sqrt(np.mean(audio_array ** 2))
    return rms

def is_silent(audio_data, threshold=SILENCE_THRESHOLD):
    """Ses verisinin sessiz olup olmadÄ±ÄŸÄ±nÄ± kontrol eder"""
    rms = calculate_rms(audio_data)
    return rms < threshold

def save_audio_file(frames, filename):
    """Ses kaydÄ±nÄ± WAV dosyasÄ± olarak kaydeder"""
    filepath = os.path.join(DATA_DIR, filename)

    with wave.open(filepath, 'wb') as wf:
        wf.setnchannels(CHANNELS)
        wf.setsampwidth(pyaudio.PyAudio().get_sample_size(FORMAT))
        wf.setframerate(RATE)
        wf.writeframes(b''.join(frames))

    print(f"Ses kaydÄ± kaydedildi: {filepath}")
    return filepath

def record_and_convert(question_number=None):
    """
    Mikrofondan ses kaydÄ± yapar ve Google Cloud STT Streaming API ile
    gerÃ§ek zamanlÄ± olarak metne dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r.
    
    Args:
        question_number: Soru numarasÄ± (1, 2, 3, ...). Belirtilirse data/soru-{n}.wav olarak kaydedilir.
    
    Returns:
        Dict: {
            'transcript': str,
            'confidence': float,
            'detected_language': str,
            'audio_file': str,
            'timestamp': str
        }
    """
    print("\nğŸ¤ KonuÅŸmaya baÅŸlayÄ±n... (Sessizlik algÄ±landÄ±ÄŸÄ±nda kayÄ±t otomatik durur)")
    
    # Google Cloud STT streaming client
    client = speech.SpeechClient()
    
    config = speech.StreamingRecognitionConfig(
        config=speech.RecognitionConfig(
            encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
            sample_rate_hertz=RATE,
            language_code="tr-TR",
            alternative_language_codes=["en-US"],
            enable_automatic_punctuation=True,
            model="latest_long",
            use_enhanced=True,
        ),
        interim_results=True,  # Ara sonuÃ§larÄ± gÃ¶ster (gerÃ§ek zamanlÄ±)
    )
    
    # PaylaÅŸÄ±lan deÄŸiÅŸkenler
    frames_for_file = []
    audio_filepath = None
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # Ses akÄ±ÅŸÄ± iÃ§in generator
    def audio_generator():
        """Mikrofon akÄ±ÅŸÄ±ndan ses verisi Ã¼retir ve API'ye gÃ¶nderir"""
        nonlocal frames_for_file, audio_filepath
        
        p = pyaudio.PyAudio()
        stream = p.open(
            format=pyaudio.paInt16,
            channels=1,
            rate=RATE,
            input=True,
            frames_per_buffer=CHUNK
        )
        
        silent_chunks = 0
        recording_started = False
        grace_period_chunks = 0  # BaÅŸlangÄ±Ã§ toleransÄ± iÃ§in sayaÃ§
        
        try:
            while True:
                data = stream.read(CHUNK, exception_on_overflow=False)
                frames_for_file.append(data)
                grace_period_chunks += 1
                
                # Ses seviyesini kontrol et
                audio_data = np.frombuffer(data, dtype=np.int16)
                volume = np.abs(audio_data).mean()
                
                # BaÅŸlangÄ±Ã§ tolerans sÃ¼resi (ilk 3 saniye)
                if grace_period_chunks <= INITIAL_GRACE_PERIOD:
                    # Ä°lk 3 saniyede ses algÄ±lanÄ±rsa kayda baÅŸla
                    if volume > SILENCE_THRESHOLD and not recording_started:
                        recording_started = True
                        print("ğŸ”´ KayÄ±t baÅŸladÄ±...", flush=True)
                    # Ä°lk 3 saniyede sessizlik sayÄ±lmaz
                    continue
                
                # Normal kayÄ±t modu (3 saniye sonra)
                if volume > SILENCE_THRESHOLD:
                    silent_chunks = 0
                    if not recording_started:
                        recording_started = True
                        print("ğŸ”´ KayÄ±t baÅŸladÄ±...", flush=True)
                else:
                    if recording_started:
                        silent_chunks += 1
                
                # Sessizlik sÃ¼resi aÅŸÄ±ldÄ±ysa dur (3 saniye sessizlik)
                if recording_started and silent_chunks > SILENCE_DURATION:
                    print("âœ… KayÄ±t tamamlandÄ±. ({:.1f} saniye)".format(len(frames_for_file) * CHUNK / RATE), flush=True)
                    break
                
                # Maksimum sÃ¼re kontrolÃ¼
                if len(frames_for_file) > (RATE / CHUNK * 60):
                    print("â±ï¸ Maksimum sÃ¼re aÅŸÄ±ldÄ±.")
                    break
                
                # API'ye gerÃ§ek zamanlÄ± gÃ¶nder
                yield speech.StreamingRecognizeRequest(audio_content=data)
        
        finally:
            stream.stop_stream()
            stream.close()
            p.terminate()
            
            # Ses dosyasÄ±nÄ± kaydet
            if question_number is not None:
                audio_filepath = os.path.join(DATA_DIR, f"soru-{question_number}.wav")
            else:
                audio_filepath = os.path.join(DATA_DIR, f"temp_recording_{timestamp}.wav")
            
            p_temp = pyaudio.PyAudio()
            with wave.open(audio_filepath, 'wb') as wf:
                wf.setnchannels(1)
                wf.setsampwidth(p_temp.get_sample_size(pyaudio.paInt16))
                wf.setframerate(RATE)
                wf.writeframes(b''.join(frames_for_file))
            p_temp.terminate()
            
            print(f"ğŸ’¾ Ses kaydedildi: {audio_filepath}")
    
    # Streaming recognition baÅŸlat
    print("ğŸ”„ GerÃ§ek zamanlÄ± transkripsiyon aktif...")
    
    try:
        requests = audio_generator()
        responses = client.streaming_recognize(config, requests)
        
        # SonuÃ§larÄ± topla
        transcript = ""
        confidence = 0.0
        detected_language = "tr-TR"
        
        for response in responses:
            if not response.results:
                continue
            
            result = response.results[0]
            
            # Final sonucu al
            if result.is_final:
                transcript = result.alternatives[0].transcript
                confidence = result.alternatives[0].confidence
                
                # Dil tespiti
                if hasattr(result, 'language_code'):
                    detected_language = result.language_code
                
                print(f"ğŸ“ {transcript}", flush=True)
            else:
                # Ara sonuÃ§larÄ± gÃ¶ster (opsiyonel)
                interim_transcript = result.alternatives[0].transcript
                print(f"â³ {interim_transcript}", end='\r', flush=True)
        
        if not transcript:
            print("\nâš ï¸ Ses algÄ±landÄ± ancak metin dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lemedi. LÃ¼tfen daha net konuÅŸun.")
            return None
        
        language_name = "TÃ¼rkÃ§e" if detected_language.startswith("tr") else "Ä°ngilizce"
        
        print(f"\nâœ… Transkripsiyon tamamlandÄ±!")
        print(f"   Metin: '{transcript}'")
        print(f"   Dil: {language_name} ({detected_language})")
        print(f"   GÃ¼venilirlik: {confidence:.2%}\n")
        
        return {
            'transcript': transcript,
            'confidence': confidence,
            'detected_language': detected_language,
            'audio_file': audio_filepath,
            'timestamp': timestamp
        }
    
    except Exception as e:
        print(f"\nâŒ Hata oluÅŸtu: {e}")
        return None

